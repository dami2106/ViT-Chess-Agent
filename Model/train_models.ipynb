{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras.models as models\n",
    "import tensorflow.keras.layers as layers\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from tensorflow import keras\n",
    "import sys \n",
    "import numpy as np \n",
    "import os \n",
    "import random\n",
    "import gzip\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow.keras.callbacks as callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the model to train, dataset for training, and side to train (from / to)\\\n",
    "model_name = sys.argv[1]\n",
    "dataset = sys.argv[2]\n",
    "side = sys.argv[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "\n",
    "learning_rate = 0.001\n",
    "weight_decay = 0.0001\n",
    "batch_size = 2048 \n",
    "num_epochs = 1000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator(Sequence):\n",
    "    def __init__(self, x_set, y_set, batch_size):\n",
    "        self.x, self.y = x_set, y_set\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.x) / float(self.batch_size)))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        batch_x = self.x[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        batch_y = self.y[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        return batch_x, batch_y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CNN(conv_size, conv_depth):\n",
    "  board_in = layers.Input(shape=(14, 8, 8))\n",
    "\n",
    "  x = board_in\n",
    "  for _ in range(conv_depth):\n",
    "    x = layers.Conv2D(filters=conv_size, kernel_size=3, padding='same', activation='relu')(x)\n",
    "  x = layers.Flatten()(x)\n",
    "  x = layers.Dense(64, 'relu')(x)\n",
    "  x = layers.Dense(64, 'softmax')(x)\n",
    "\n",
    "  return models.Model(inputs=board_in, outputs=x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def residual(conv_size, conv_depth):\n",
    "  board_in = layers.Input(shape=(14, 8, 8))\n",
    "\n",
    "  x = layers.Conv2D(filters=conv_size, kernel_size=3, padding='same')(board_in)\n",
    "  for _ in range(conv_depth):\n",
    "    previous = x\n",
    "    x = layers.Conv2D(filters=conv_size, kernel_size=3, padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    x = layers.Conv2D(filters=conv_size, kernel_size=3, padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Add()([x, previous])\n",
    "    x = layers.Activation('relu')(x)\n",
    "  x = layers.Flatten()(x)\n",
    "  x = layers.Dense(64, 'softmax')(x)\n",
    "\n",
    "  return models.Model(inputs=board_in, outputs=x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vit():\n",
    "    num_classes = 64\n",
    "    input_shape = (8, 8, 14)\n",
    "    patch_size = 2  # Size of the patches to be extract from the input images\n",
    "    num_patches = (8 // patch_size) ** 2\n",
    "    projection_dim = 176\n",
    "    num_heads = 3\n",
    "    transformer_units = [\n",
    "        projection_dim * 2,\n",
    "        projection_dim,\n",
    "    ]  # Size of the transformer layers\n",
    "    transformer_layers = 4\n",
    "    mlp_head_units = [512, 1984]  # Size of the dense layers of the final classifier\n",
    "\n",
    "    \n",
    "    def mlp(x, hidden_units, dropout_rate):\n",
    "        for units in hidden_units:\n",
    "            x = layers.Dense(units, activation=tf.nn.gelu)(x)\n",
    "            x = layers.Dropout(dropout_rate)(x)\n",
    "        return x\n",
    "    class Patches(layers.Layer):\n",
    "        def __init__(self, patch_size):\n",
    "            super().__init__()\n",
    "            self.patch_size = patch_size\n",
    "\n",
    "        def call(self, images):\n",
    "            batch_size = tf.shape(images)[0]\n",
    "            patches = tf.image.extract_patches(\n",
    "                images=images,\n",
    "                sizes=[1, self.patch_size, self.patch_size, 1],\n",
    "                strides=[1, self.patch_size, self.patch_size, 1],\n",
    "                rates=[1, 1, 1, 1],\n",
    "                padding=\"VALID\",\n",
    "            )\n",
    "            patch_dims = patches.shape[-1]\n",
    "            patches = tf.reshape(patches, [batch_size, -1, patch_dims])\n",
    "            return patches\n",
    "\n",
    "    class PatchEncoder(layers.Layer):\n",
    "        def __init__(self, num_patches, projection_dim):\n",
    "            super().__init__()\n",
    "            self.num_patches = num_patches\n",
    "            self.projection = layers.Dense(units=projection_dim)\n",
    "            self.position_embedding = layers.Embedding(\n",
    "                input_dim=num_patches, output_dim=projection_dim\n",
    "            )\n",
    "\n",
    "        def call(self, patch):\n",
    "            positions = tf.range(start=0, limit=self.num_patches, delta=1)\n",
    "            encoded = self.projection(patch) + self.position_embedding(positions)\n",
    "            return encoded\n",
    "\n",
    "    def create_vit_classifier():\n",
    "        inputs = layers.Input(shape=input_shape)\n",
    "        # Create patches.\n",
    "        patches = Patches(patch_size)(inputs)\n",
    "        # Encode patches.\n",
    "        encoded_patches = PatchEncoder(num_patches, projection_dim)(patches)\n",
    "\n",
    "        # Create multiple layers of the Transformer block.\n",
    "        for _ in range(transformer_layers):\n",
    "            # Layer normalization 1.\n",
    "            x1 = layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n",
    "            # Create a multi-head attention layer.\n",
    "            attention_output = layers.MultiHeadAttention(\n",
    "                num_heads=num_heads, key_dim=projection_dim, dropout=0.1\n",
    "            )(x1, x1)\n",
    "            # Skip connection 1.\n",
    "            x2 = layers.Add()([attention_output, encoded_patches])\n",
    "            # Layer normalization 2.\n",
    "            x3 = layers.LayerNormalization(epsilon=1e-6)(x2)\n",
    "            # MLP.\n",
    "            x3 = mlp(x3, hidden_units=transformer_units, dropout_rate=0.1)\n",
    "            # Skip connection 2.\n",
    "            encoded_patches = layers.Add()([x3, x2])\n",
    "\n",
    "        # Create a [batch_size, projection_dim] tensor.\n",
    "        representation = layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n",
    "        representation = layers.Flatten()(representation)\n",
    "        representation = layers.Dropout(0.5)(representation)\n",
    "        # Add MLP.\n",
    "        features = mlp(representation, hidden_units=mlp_head_units, dropout_rate=0.5)\n",
    "        # Classify outputs.\n",
    "        logits = layers.Dense(num_classes)(features)\n",
    "        # Create the Keras model.\n",
    "        model = keras.Model(inputs=inputs, outputs=logits)\n",
    "\n",
    "        return model\n",
    "    \n",
    "    return create_vit_classifier()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = None\n",
    "if model_name == 'CNN':\n",
    "    model = CNN(32, 4)\n",
    "    model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\n",
    "        keras.metrics.CategoricalAccuracy(name=\"accuracy\"),\n",
    "        keras.metrics.TopKCategoricalAccuracy(5, name=\"top-5-accuracy\"),\n",
    "    ])\n",
    "\n",
    "elif model_name == 'residual':\n",
    "    model = residual(32, 4)\n",
    "    model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\n",
    "        keras.metrics.CategoricalAccuracy(name=\"accuracy\"),\n",
    "        keras.metrics.TopKCategoricalAccuracy(5, name=\"top-5-accuracy\"),\n",
    "    ])\n",
    "\n",
    "elif model_name == 'vit':\n",
    "    model = vit()\n",
    "    optimizer = tf.keras.optimizers.Adam(\n",
    "        learning_rate=learning_rate, decay=weight_decay\n",
    "    )\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss=keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "        metrics=[\n",
    "            keras.metrics.CategoricalAccuracy(name=\"accuracy\"),\n",
    "            keras.metrics.TopKCategoricalAccuracy(5, name=\"top-5-accuracy\"),\n",
    "        ],\n",
    "    )\n",
    "\n",
    "else:\n",
    "    print('Invalid model name')\n",
    "    exit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_folder = f\"{model_name}_{dataset}_models\"\n",
    "if not os.path.exists(model_folder):\n",
    "    os.makedirs(model_folder)\n",
    "    print(f\"Created folder '{model_folder}'.\")\n",
    "\n",
    "if not os.path.exists(model_folder + \"/logs\"):\n",
    "    os.makedirs(model_folder + \"/logs\")\n",
    "    print(f\"Created folder '{model_folder}/logs'.\")\n",
    "\n",
    "if not os.path.exists(model_folder + \"/models\"):\n",
    "    os.makedirs(model_folder + \"/models\")\n",
    "    print(f\"Created folder '{model_folder}/models'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Training {model_name}_{dataset}_{side}.\")\n",
    "\n",
    "f = gzip.GzipFile(f\"{dataset}/boards.npy.gz\", \"r\")\n",
    "board = np.load(f)\n",
    "f.close()\n",
    "\n",
    "f = gzip.GzipFile(f\"{dataset}/{side}.npy.gz\", \"r\")\n",
    "labels = np.load(f)\n",
    "f.close()\n",
    "\n",
    "assert board.shape[0] == labels.shape[0]\n",
    "\n",
    "if model_name == 'vit':\n",
    "    #board = np.transpose(board, (0, 2, 3, 1))\n",
    "    print(\"Shape : \", board.shape)\n",
    "    board = np.moveaxis(board, 1, -1)\n",
    "\n",
    "X_train, X_validate, y_train, y_validate = train_test_split(board, labels, test_size=0.1, random_state=SEED)\n",
    "board = None\n",
    "labels = None\n",
    "\n",
    "train_gen = DataGenerator(X_train, y_train, batch_size)\n",
    "valid_gen = DataGenerator(X_validate, y_validate, batch_size)\n",
    "\n",
    "history = model.fit(train_gen, epochs=num_epochs, validation_data=valid_gen, callbacks=[ \n",
    "    callbacks.ReduceLROnPlateau(monitor='loss', patience=10),\n",
    "    callbacks.EarlyStopping(monitor='loss', patience=15, min_delta=1e-4, restore_best_weights=True),\n",
    "    callbacks.CSVLogger(f\"{model_folder}/logs/{model_name}_{dataset}_{side}.csv\", separator=\",\", append=True)\n",
    "    ])\n",
    "\n",
    "model.save(f\"{model_folder}/models/{model_name}_{dataset}_{side}.tf\", save_format='tf')\n",
    "print(f\"Saved model : {model_folder}/models/{model_name}_{dataset}_{side}.tf\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(f\"{model_folder}/{model_name}_{dataset}_{side}_information.txt\", \"w\")\n",
    "f.write(\"Model Name : {}\\n\".format(model_name))\n",
    "f.write(\"Dataset used : \\n\".format(dataset))\n",
    "f.write(\"Side trained on : {}\\n\".format(side))\n",
    "f.write(\"Seed : {}\\n\".format(SEED))\n",
    "f.write(\"Batch Size : {}\\n\".format(batch_size))\n",
    "f.close()\n",
    "print(\"Done!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BC_Chess_agent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
